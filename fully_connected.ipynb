{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fully_connected.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPD5G9UJJka76aOSOz8nzfk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/patbaa/demo_notebooks/blob/master/fully_connected.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQzk1oS1Bce2",
        "colab_type": "text"
      },
      "source": [
        "# Our first fully connected neural network in TensorFlow/Keras\n",
        "\n",
        "This example notebook provides a small example how to implement and train a fully connected neural network via TensoFlow/Keras on the MNIST handwritten digits dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XES3bgMHGT6",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"http://patbaa.web.elte.hu/fcn.png\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcC-W4rXFpKu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDn_WhJTcndA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6TaFgyGHsMy",
        "colab_type": "text"
      },
      "source": [
        "# Load MNIST data, check its dimensions and let's look at a few random examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "masxuYFdDeTj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jZt6G4FDk1Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAH7D5J4DoQk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_train_imgs(n=8, m=5):\n",
        "    for i in range(m):\n",
        "        for j in range(n):\n",
        "            idx = np.random.randint(len(y_train))\n",
        "            plt.subplot(int('1' + str(n) + str(j+1)))\n",
        "            plt.imshow(x_train[idx], cmap='gray')\n",
        "            plt.title(y_train[idx], fontsize=30)\n",
        "            plt.axis('off')\n",
        "        plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WvNGKMoDyEw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.rcParams['figure.figsize'] = (15, 5)\n",
        "show_train_imgs(8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hI7vz5nmD2vx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train.min(), x_train.max()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8zaAWRZH4ym",
        "colab_type": "text"
      },
      "source": [
        "### Normalize data & reshape to a 1D array instead of 2D matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbUrWgBKD4uG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train.reshape(60000, 28*28)/255\n",
        "x_test = x_test.reshape(10000, 28*28)/255\n",
        "\n",
        "x_train.shape, x_test.shape, x_train.min(), x_train.max()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wWWVG4fEAua",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train[:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewe_ObH5ICO0",
        "colab_type": "text"
      },
      "source": [
        "## Conversion of the labels to one-hot encoded labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHeHkxSeD893",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train_oh = keras.utils.to_categorical(y_train)\n",
        "y_test_oh = keras.utils.to_categorical(y_test)\n",
        "y_train_oh[:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hh9SLXGbIIBg",
        "colab_type": "text"
      },
      "source": [
        "# We will use the so called Sequential API. \n",
        "### This API let's us to build neural networks with the following limitation: each layer's input is the output of the previous layer to build more flexible neural networks we will use the Functional API\n",
        "\n",
        "The Sequential API...\n",
        "  - builds up layer-by-layer\n",
        "  - you can pass activation functions as an argument to most of the layers\n",
        "  - or you can create activation layer\n",
        "  - .summary() \n",
        "  - model needs to be compiled before training\n",
        "    - you need to set the loss function\n",
        "    - optimizer\n",
        "    - metrics\n",
        "    - any callbacks (functions to run after/before epochs, batches, etc)\n",
        "  - after compiling you may train your model\n",
        "    - #epochs\n",
        "    - batch size\n",
        "    - train data\n",
        "    - validation data can be provided\n",
        "  - you can also generate predictions with a trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1uE4g9hBl0A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Dense(784, activation='relu', input_dim=784))\n",
        "model.add(keras.layers.Dense(512, activation='relu'))\n",
        "model.add(keras.layers.Dense(256, activation='relu'))\n",
        "model.add(keras.layers.Dense(128, activation='relu'))\n",
        "model.add(keras.layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uf68FGACIIV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVFKSYyfCb51",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "784*784+784, 784*512+512, 512*256+256, 256*128+128, 128*10+10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfKzuuMRDGti",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.SGD(lr=1e-2), metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlVA-HH_EIAl",
        "colab_type": "text"
      },
      "source": [
        "# With GPU 1 epoch ~3s. \n",
        "If you feel your model is much slower activate GPU on Google Colab via Runtime $\\to$ Change runtime type $\\to$ Hardware acceleraton $\\to$ GPU\n",
        "During training the most importrant summary is shown. You can also save trianing history."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eG11BTseDThc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(x=x_train, y=y_train_oh, batch_size=64, epochs=15, validation_data=(x_test, y_test_oh))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbVX8lZTEENW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(history.history['loss'], label='train loss')\n",
        "plt.plot(history.history['val_loss'], label='val loss')\n",
        "plt.xlabel('epochs', fontsize=15)\n",
        "plt.legend(fontsize=20)\n",
        "plt.show()\n",
        "plt.plot(history.history['accuracy'], label='train accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='val accuracy')\n",
        "plt.xlabel('epochs', fontsize=15)\n",
        "plt.legend(fontsize=20)\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zThtwvkeKWHy",
        "colab_type": "text"
      },
      "source": [
        "# >97%, not too bad, but why not 100%?\n",
        "Let's check the predictions, where the model goes wrong. Errorneous predictions are highlighted with a red dot. Also, from the learning curves above we can see, that the model is still not fully trained, the results are still improving."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4A4F5D0pEOhH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_predictions(n=5, m=5):\n",
        "    for j in range(m):\n",
        "        idx_start = np.random.randint(len(x_test) - n)\n",
        "        preds = model.predict(x_test[idx_start:idx_start+5])\n",
        "        true_labels = y_test[idx_start:idx_start+5]\n",
        "\n",
        "        for i in range(n):\n",
        "            plt.subplot(int('1' + str(n) + str(i+1)))\n",
        "            predstr = 'pred: ' + str(preds[i].argmax()) + ', prob: ' + str(int(np.round(preds[i].max()*100,0))) + '%'\n",
        "            plt.title(predstr + ' / true: ' + str(true_labels[i]),fontsize=10)\n",
        "            plt.imshow(x_test[idx_start+i].reshape(28, 28)*255, cmap='gray')\n",
        "            if(preds[i].argmax() != true_labels[i]):\n",
        "                plt.scatter([14], [14], s=500, c='r')\n",
        "            plt.axis('off')\n",
        "        plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvy0Am_GEPLK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show_predictions(m=20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OZrnO-dKv5y",
        "colab_type": "text"
      },
      "source": [
        "# What accuracy can you achieve with a 5-layer fully connected neural network?"
      ]
    }
  ]
}