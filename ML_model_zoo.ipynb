{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_model_zoo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNo6rlVnFN3zbtsiy8rrEPH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/patbaa/demo_notebooks/blob/master/ML_model_zoo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPOYkOZPM-sg",
        "colab_type": "text"
      },
      "source": [
        "# Machine learning model ZOO\n",
        "\n",
        "Nowadays everyone talks about 'artificial intelligence', in every research paper one can read 'deep learning'. In reality many of the work is done by traditional machine learning models. These models live with us for decades now and do a descent job with their limitations.\n",
        "\n",
        "Usually traditional machine learning models are easier to interpret and understand their learnt underlying decision process than neural networks. The rule of thumb is that when it comes to images, audio files or text, modern neural networks are superior than traditional machine learning methods, on the other hand when we work with traditional tabular data it often goes the opposite way. It worth to study the winning solutions on [Kaggle](https://www.kaggle.com/) to see the usual winning models for different datatypes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaJElhqxiXRB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np # np array & math\n",
        "import pandas as pd # to handle data table\n",
        "import seaborn as sns # high-level plotting package, built on matplotlib\n",
        "import matplotlib.pyplot as plt # lower-level plotting package\n",
        "\n",
        "from collections import Counter\n",
        "# super useful function to count objects in lists\n",
        "\n",
        "%matplotlib inline\n",
        "# to have the plots displayed within the notebook\n",
        "\n",
        "\n",
        "from sklearn import datasets, cluster\n",
        "from sklearn import neighbors, ensemble, tree, linear_model\n",
        "from sklearn import model_selection, metrics\n",
        "# sklearn in the most popular machine learning library in python"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHx4mXg52I-W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = datasets.load_breast_cancer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l77XJIbW4cSs",
        "colab_type": "text"
      },
      "source": [
        "# Breast Cancer Wisconsin (Diagnostic) Data Set\n",
        "\n",
        "Fine needle aspirate (FNA) of a breast mass. The dataset contains extracted information of cell nuclei from digitized images.\n",
        "\n",
        "A few extracted information:\n",
        " - radius\n",
        " - texture\n",
        " - perimeter\n",
        " - area\n",
        " - smoothness\n",
        " - compactness\n",
        "\n",
        " The target variable is binary, the diagnosis (M malignant - 0, B benign - 1)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_xF_bUz38wo",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/6/65/Pancreas_FNA%3B_adenocarcinoma_vs._normal_ductal_epithelium_%28400x%29_%28322383635%29.jpg\" align=\"middle\">\n",
        "\n",
        "Image: By Ed Uthman from Houston, TX, USA - Pancreas FNA; adenocarcinoma vs. normal ductal epithelium (400x)Uploaded by CFCF, CC BY 2.0, https://commons.wikimedia.org/w/index.php?curid=30103637\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Df6QrYS5g77",
        "colab_type": "text"
      },
      "source": [
        "# Get familiar with the data\n",
        " - missing values\n",
        " - range of features\n",
        " - strange behaviours, outliers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8v0diwDh3eT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = pd.DataFrame(data['data'])\n",
        "X.columns = data['feature_names']\n",
        "X.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKpVCv89j8kj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Counter(data['target'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "my577F0JJboE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['target_names']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nTBH55hkAiI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fibhjG8CkCCV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(X.T.isna())\n",
        "print(f'# NAs: {X.isna().sum().sum()}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyxORPVi8soW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X['target'] = data.target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ozlp9aB95vHV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.hist(X[X['target'] == 0]['mean radius'], alpha = 0.7, label='malignant', bins=20)\n",
        "plt.hist(X[X['target'] == 1]['mean radius'], alpha = 0.7, label='benign', bins=20)\n",
        "plt.xlabel('mean radius', fontsize=15)\n",
        "plt.legend(fontsize=15)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UXrOKbK6vXJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(20, 7))\n",
        "data2 = pd.concat([X.target, ((X-X.mean())/X.std()).drop('target', 1)], axis=1)\n",
        "data2 = pd.melt(data2,id_vars=\"target\",\n",
        "                    var_name=\"features\",\n",
        "                    value_name='value')\n",
        "sns.violinplot(x=\"features\", y=\"value\", hue=\"target\", data=data2, split=True, inner=\"quart\")\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_m295WE69WR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(14, 14))\n",
        "sns.heatmap(X.corr(), annot=True, linewidths=.5, fmt= '.1f')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-4i59qJ7Ql0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(14, 14))\n",
        "sns.clustermap(X.T)\n",
        "sns.clustermap(((X-X.mean())/X.std()).T)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vkpLAuCKgrO",
        "colab_type": "text"
      },
      "source": [
        "# Impute missing data when needed **always with care**\n",
        " - is the missingness random?\n",
        " - is the missingness portion significant?\n",
        " - remove feature / samples\n",
        " - fill with mean / median\n",
        " - new feature: is_missing ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1kgQJfTBSoD",
        "colab_type": "text"
      },
      "source": [
        "# Modeling\n",
        " - KMeans clustering - 2 clusters\n",
        " - Decision tree classifier\n",
        " - Random forest with feature importance \n",
        " - Logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BSymDxwoDOCC",
        "colab": {}
      },
      "source": [
        "kmeans = cluster.KMeans(n_clusters=2, random_state=42)\n",
        "rf     = ensemble.RandomForestClassifier(random_state=42)\n",
        "dt     = tree.DecisionTreeClassifier()\n",
        "lr     = linear_model.LogisticRegression()\n",
        "knn    = neighbors.KNeighborsClassifier(5) \n",
        "\n",
        "# random states are important for reproducibility"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-9fHNoIDW_q",
        "colab_type": "text"
      },
      "source": [
        "## KMeans is unsupervised, the rest is supervised"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GgllhTADcAY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kmeans_clusters = kmeans.fit_predict(X.drop('target', 1), X['target'])\n",
        "(kmeans_clusters == X['target']).mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgw692UeJhH8",
        "colab_type": "text"
      },
      "source": [
        "KNN does not know which cluster is which!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4c9MMswFDxdh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kmeans_clusters = np.array([1 if i == 0 else 0 for i in kmeans_clusters])\n",
        "(kmeans_clusters == X['target']).mean()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeNnnKo4zqPF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cm = metrics.confusion_matrix(y_true=X['target'],y_pred=kmeans_clusters)\n",
        "sns.heatmap(cm,annot=True,fmt=\"d\")\n",
        "plt.xlabel('prediction', fontsize=15)\n",
        "plt.ylabel('label', fontsize=15)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1HpzsUrEPEU",
        "colab_type": "text"
      },
      "source": [
        "## Supervised models. Everything is with default values!\n",
        " - K-fold cross-validation, with K=5\n",
        " - Leave-one-out is when K=len(X)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37tbTm3sDC2w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rf_preds   = model_selection.cross_val_predict(rf, X.drop('target', 1), \n",
        "                               X['target'], method='predict_proba', cv=5)\n",
        "tree_preds = model_selection.cross_val_predict(dt, X.drop('target', 1), \n",
        "                               X['target'], method='predict_proba', cv=5)\n",
        "lr_preds   = model_selection.cross_val_predict(lr, X.drop('target', 1), \n",
        "                               X['target'], method='predict_proba', cv=5)\n",
        "knn_preds  = model_selection.cross_val_predict(knn, X.drop('target', 1), \n",
        "                               X['target'], method='predict_proba', cv=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjHgyHNoIafl",
        "colab_type": "text"
      },
      "source": [
        "# ConvergenceWarning...\n",
        " - increase iteration limit\n",
        " - scale data\n",
        " - learning rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQtuvGiSz2QM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(8, 8))\n",
        "for idx, preds in enumerate([rf_preds, tree_preds, lr_preds, knn_preds]):\n",
        "    fpr, tpr, _ = metrics.roc_curve(y_score=preds[:,1], y_true=data['target'])\n",
        "    auc = np.round(metrics.roc_auc_score(y_score=preds[:,1], y_true=data['target']), 3)\n",
        "    plt.plot(fpr, tpr, label=['random forest', 'decision tree', \n",
        "                             'logistic regression', 'knn'][idx] + f': {auc}')\n",
        "plt.legend(fontsize=15)\n",
        "plt.plot([0, 1], [0, 1], '--', c='k')\n",
        "plt.xlabel('False Positive Rate', fontsize=15)\n",
        "plt.ylabel('True Positive Rate', fontsize=15)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4JghJ40Ij88",
        "colab_type": "text"
      },
      "source": [
        "## Why do we have just...\n",
        " - one break point for decision tree\n",
        " - a few break points for KNN?\n",
        "\n",
        "**Remember: ROC curve is generated with sweeping the probability threshold! Can these models provide real, continuous probabilities?**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGwIgSyoz3TQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = X.set_index('target')\n",
        "X = (X - X.mean())/X.std()\n",
        "X = X.reset_index()\n",
        "rf_preds2   = model_selection.cross_val_predict(rf, X.drop('target', 1), \n",
        "                               X['target'], method='predict_proba', cv=5)\n",
        "tree_preds2 = model_selection.cross_val_predict(dt, X.drop('target', 1), \n",
        "                               X['target'], method='predict_proba', cv=5)\n",
        "lr_preds2   = model_selection.cross_val_predict(lr, X.drop('target', 1), \n",
        "                               X['target'], method='predict_proba', cv=5)\n",
        "knn_preds2  = model_selection.cross_val_predict(knn, X.drop('target', 1), \n",
        "                               X['target'], method='predict_proba', cv=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnXjPzthz6CW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(16, 8))\n",
        "plt.subplot(121)\n",
        "for idx, preds in enumerate([rf_preds, tree_preds, lr_preds, knn_preds]):\n",
        "    fpr, tpr, _ = metrics.roc_curve(y_score=preds[:,1], y_true=data['target'])\n",
        "    auc = np.round(metrics.roc_auc_score(y_score=preds[:,1], y_true=data['target']), 3)\n",
        "    plt.plot(fpr, tpr, label=['random forest', 'decision tree', \n",
        "                             'logistic regression', 'knn'][idx] + f': {auc}')\n",
        "plt.legend(fontsize=15)\n",
        "plt.plot([0, 1], [0, 1], '--', c='k')\n",
        "plt.xlabel('False Positive Rate', fontsize=15)\n",
        "plt.ylabel('True Positive Rate', fontsize=15)\n",
        "plt.title('Without normalization', fontsize=20)\n",
        "\n",
        "plt.subplot(122)\n",
        "for idx, preds in enumerate([rf_preds2, tree_preds2, lr_preds2, knn_preds2]):\n",
        "    fpr, tpr, _ = metrics.roc_curve(y_score=preds[:,1], y_true=data['target'])\n",
        "    auc = np.round(metrics.roc_auc_score(y_score=preds[:,1], y_true=data['target']), 3)\n",
        "    plt.plot(fpr, tpr, label=['random forest', 'decision tree', \n",
        "                             'logistic regression', 'knn'][idx] + f': {auc}')\n",
        "plt.legend(fontsize=15)\n",
        "plt.plot([0, 1], [0, 1], '--', c='k')\n",
        "plt.xlabel('False Positive Rate', fontsize=15)\n",
        "plt.ylabel('True Positive Rate', fontsize=15)\n",
        "plt.title('With normalization', fontsize=20)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgLhbfweEv3P",
        "colab_type": "text"
      },
      "source": [
        "# Summary:\n",
        " - some models are sensitive for input data scale\n",
        " - use sklearn, one of the best package for ML purposes in Python\n",
        "   - clean API\n",
        "   - standard\n",
        "   - community\n",
        " - there is no overall best model\n",
        "   - Kaggle competitions are often won by\n",
        "     - tree based models (with tabular data)\n",
        "     - convolutional neural networks (images, sound, text)\n",
        "   - but the best model is data dependent\n",
        " - also model interpretability can be important \n",
        "\n",
        "\n",
        " Also there are models outside of sklearn. Such as\n",
        "  - [XGBoost](https://github.com/dmlc/xgboost)\n",
        "  - [LightGBM](https://github.com/microsoft/LightGBM)\n",
        "\n"
      ]
    }
  ]
}